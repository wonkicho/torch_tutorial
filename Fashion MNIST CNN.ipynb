{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms,datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "batch_size= 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST('../data',train=True, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,),(0.3081,))\n",
    "    ])),\n",
    "    batch_size = batch_size, shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST('../data',train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,),(0.3081,))\n",
    "    ])),\n",
    "    batch_size = batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10,kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10,20, kernel_size=5)\n",
    "        self.drop = nn.Dropout2d()\n",
    "        \n",
    "        self.fc1 = nn.Linear(320,50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "        x= F.relu(F.max_pool2d(self.conv2(x),2))\n",
    "        x = x.view(-1,320)\n",
    "        \n",
    "        x= F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x= self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        data,target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss=F.cross_entropy(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 200 == 0:\n",
    "            print('Train Epoch : {}, [{}/{} ({:.0f}%)]\\t Loss : {:.6f}'.format(epoch,batch_idx*len(data),len(train_loader.dataset),100.*batch_idx/len(train_loader),loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalauate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data,target in test_loader:\n",
    "            data,target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += F.cross_entropy(output,target,reduction='sum').item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch : 1, [0/60000 (0%)]\t Loss : 1.071738\n",
      "Train Epoch : 1, [12800/60000 (21%)]\t Loss : 0.850949\n",
      "Train Epoch : 1, [25600/60000 (43%)]\t Loss : 1.020160\n",
      "Train Epoch : 1, [38400/60000 (64%)]\t Loss : 0.927595\n",
      "Train Epoch : 1, [51200/60000 (85%)]\t Loss : 0.918161\n",
      "[1] Test Loss : 0.7385, Acc : 72.96%\n",
      "Train Epoch : 2, [0/60000 (0%)]\t Loss : 0.704000\n",
      "Train Epoch : 2, [12800/60000 (21%)]\t Loss : 0.971825\n",
      "Train Epoch : 2, [25600/60000 (43%)]\t Loss : 0.921776\n",
      "Train Epoch : 2, [38400/60000 (64%)]\t Loss : 0.873138\n",
      "Train Epoch : 2, [51200/60000 (85%)]\t Loss : 0.809617\n",
      "[2] Test Loss : 0.7051, Acc : 73.64%\n",
      "Train Epoch : 3, [0/60000 (0%)]\t Loss : 0.745469\n",
      "Train Epoch : 3, [12800/60000 (21%)]\t Loss : 0.750270\n",
      "Train Epoch : 3, [25600/60000 (43%)]\t Loss : 0.706826\n",
      "Train Epoch : 3, [38400/60000 (64%)]\t Loss : 0.832731\n",
      "Train Epoch : 3, [51200/60000 (85%)]\t Loss : 0.661748\n",
      "[3] Test Loss : 0.6808, Acc : 74.86%\n",
      "Train Epoch : 4, [0/60000 (0%)]\t Loss : 0.848404\n",
      "Train Epoch : 4, [12800/60000 (21%)]\t Loss : 0.924771\n",
      "Train Epoch : 4, [25600/60000 (43%)]\t Loss : 0.680537\n",
      "Train Epoch : 4, [38400/60000 (64%)]\t Loss : 0.615136\n",
      "Train Epoch : 4, [51200/60000 (85%)]\t Loss : 0.592532\n",
      "[4] Test Loss : 0.6555, Acc : 75.48%\n",
      "Train Epoch : 5, [0/60000 (0%)]\t Loss : 0.806925\n",
      "Train Epoch : 5, [12800/60000 (21%)]\t Loss : 0.590164\n",
      "Train Epoch : 5, [25600/60000 (43%)]\t Loss : 0.651845\n",
      "Train Epoch : 5, [38400/60000 (64%)]\t Loss : 0.738340\n",
      "Train Epoch : 5, [51200/60000 (85%)]\t Loss : 0.884303\n",
      "[5] Test Loss : 0.6449, Acc : 75.62%\n",
      "Train Epoch : 6, [0/60000 (0%)]\t Loss : 0.588817\n",
      "Train Epoch : 6, [12800/60000 (21%)]\t Loss : 0.674895\n",
      "Train Epoch : 6, [25600/60000 (43%)]\t Loss : 1.071413\n",
      "Train Epoch : 6, [38400/60000 (64%)]\t Loss : 0.631837\n",
      "Train Epoch : 6, [51200/60000 (85%)]\t Loss : 0.597894\n",
      "[6] Test Loss : 0.6241, Acc : 76.27%\n",
      "Train Epoch : 7, [0/60000 (0%)]\t Loss : 0.689426\n",
      "Train Epoch : 7, [12800/60000 (21%)]\t Loss : 0.580653\n",
      "Train Epoch : 7, [25600/60000 (43%)]\t Loss : 0.624361\n",
      "Train Epoch : 7, [38400/60000 (64%)]\t Loss : 0.511186\n",
      "Train Epoch : 7, [51200/60000 (85%)]\t Loss : 0.818811\n",
      "[7] Test Loss : 0.6184, Acc : 76.78%\n",
      "Train Epoch : 8, [0/60000 (0%)]\t Loss : 0.788945\n",
      "Train Epoch : 8, [12800/60000 (21%)]\t Loss : 0.655539\n",
      "Train Epoch : 8, [25600/60000 (43%)]\t Loss : 0.586053\n",
      "Train Epoch : 8, [38400/60000 (64%)]\t Loss : 0.731796\n",
      "Train Epoch : 8, [51200/60000 (85%)]\t Loss : 0.557377\n",
      "[8] Test Loss : 0.5981, Acc : 77.23%\n",
      "Train Epoch : 9, [0/60000 (0%)]\t Loss : 0.655840\n",
      "Train Epoch : 9, [12800/60000 (21%)]\t Loss : 0.740998\n",
      "Train Epoch : 9, [25600/60000 (43%)]\t Loss : 0.758102\n",
      "Train Epoch : 9, [38400/60000 (64%)]\t Loss : 0.843904\n",
      "Train Epoch : 9, [51200/60000 (85%)]\t Loss : 0.687436\n",
      "[9] Test Loss : 0.5843, Acc : 77.93%\n",
      "Train Epoch : 10, [0/60000 (0%)]\t Loss : 0.680785\n",
      "Train Epoch : 10, [12800/60000 (21%)]\t Loss : 0.645206\n",
      "Train Epoch : 10, [25600/60000 (43%)]\t Loss : 0.612930\n",
      "Train Epoch : 10, [38400/60000 (64%)]\t Loss : 0.969801\n",
      "Train Epoch : 10, [51200/60000 (85%)]\t Loss : 0.731857\n",
      "[10] Test Loss : 0.5725, Acc : 78.20%\n",
      "Train Epoch : 11, [0/60000 (0%)]\t Loss : 0.811991\n",
      "Train Epoch : 11, [12800/60000 (21%)]\t Loss : 0.520598\n",
      "Train Epoch : 11, [25600/60000 (43%)]\t Loss : 0.756027\n",
      "Train Epoch : 11, [38400/60000 (64%)]\t Loss : 0.581542\n",
      "Train Epoch : 11, [51200/60000 (85%)]\t Loss : 0.484503\n",
      "[11] Test Loss : 0.5716, Acc : 77.53%\n",
      "Train Epoch : 12, [0/60000 (0%)]\t Loss : 0.687628\n",
      "Train Epoch : 12, [12800/60000 (21%)]\t Loss : 0.730025\n",
      "Train Epoch : 12, [25600/60000 (43%)]\t Loss : 0.654206\n",
      "Train Epoch : 12, [38400/60000 (64%)]\t Loss : 0.495676\n",
      "Train Epoch : 12, [51200/60000 (85%)]\t Loss : 0.752822\n",
      "[12] Test Loss : 0.5570, Acc : 78.62%\n",
      "Train Epoch : 13, [0/60000 (0%)]\t Loss : 0.555248\n",
      "Train Epoch : 13, [12800/60000 (21%)]\t Loss : 0.389720\n",
      "Train Epoch : 13, [25600/60000 (43%)]\t Loss : 0.583780\n",
      "Train Epoch : 13, [38400/60000 (64%)]\t Loss : 0.613237\n",
      "Train Epoch : 13, [51200/60000 (85%)]\t Loss : 0.689615\n",
      "[13] Test Loss : 0.5493, Acc : 78.81%\n",
      "Train Epoch : 14, [0/60000 (0%)]\t Loss : 0.597733\n",
      "Train Epoch : 14, [12800/60000 (21%)]\t Loss : 0.499542\n",
      "Train Epoch : 14, [25600/60000 (43%)]\t Loss : 0.714123\n",
      "Train Epoch : 14, [38400/60000 (64%)]\t Loss : 0.808581\n",
      "Train Epoch : 14, [51200/60000 (85%)]\t Loss : 0.709710\n",
      "[14] Test Loss : 0.5458, Acc : 79.25%\n",
      "Train Epoch : 15, [0/60000 (0%)]\t Loss : 0.600572\n",
      "Train Epoch : 15, [12800/60000 (21%)]\t Loss : 0.716430\n",
      "Train Epoch : 15, [25600/60000 (43%)]\t Loss : 0.635928\n",
      "Train Epoch : 15, [38400/60000 (64%)]\t Loss : 0.581100\n",
      "Train Epoch : 15, [51200/60000 (85%)]\t Loss : 0.625711\n",
      "[15] Test Loss : 0.5376, Acc : 80.66%\n",
      "Train Epoch : 16, [0/60000 (0%)]\t Loss : 0.523789\n",
      "Train Epoch : 16, [12800/60000 (21%)]\t Loss : 0.737052\n",
      "Train Epoch : 16, [25600/60000 (43%)]\t Loss : 1.018880\n",
      "Train Epoch : 16, [38400/60000 (64%)]\t Loss : 0.575341\n",
      "Train Epoch : 16, [51200/60000 (85%)]\t Loss : 0.538514\n",
      "[16] Test Loss : 0.5255, Acc : 80.42%\n",
      "Train Epoch : 17, [0/60000 (0%)]\t Loss : 0.579940\n",
      "Train Epoch : 17, [12800/60000 (21%)]\t Loss : 0.595773\n",
      "Train Epoch : 17, [25600/60000 (43%)]\t Loss : 0.585511\n",
      "Train Epoch : 17, [38400/60000 (64%)]\t Loss : 0.582581\n",
      "Train Epoch : 17, [51200/60000 (85%)]\t Loss : 0.704202\n",
      "[17] Test Loss : 0.5188, Acc : 81.18%\n",
      "Train Epoch : 18, [0/60000 (0%)]\t Loss : 0.503155\n",
      "Train Epoch : 18, [12800/60000 (21%)]\t Loss : 0.511470\n",
      "Train Epoch : 18, [25600/60000 (43%)]\t Loss : 0.599891\n",
      "Train Epoch : 18, [38400/60000 (64%)]\t Loss : 0.580397\n",
      "Train Epoch : 18, [51200/60000 (85%)]\t Loss : 0.608115\n",
      "[18] Test Loss : 0.5243, Acc : 80.91%\n",
      "Train Epoch : 19, [0/60000 (0%)]\t Loss : 0.568534\n",
      "Train Epoch : 19, [12800/60000 (21%)]\t Loss : 0.627903\n",
      "Train Epoch : 19, [25600/60000 (43%)]\t Loss : 0.560372\n",
      "Train Epoch : 19, [38400/60000 (64%)]\t Loss : 0.569428\n",
      "Train Epoch : 19, [51200/60000 (85%)]\t Loss : 0.544099\n",
      "[19] Test Loss : 0.5113, Acc : 81.00%\n",
      "Train Epoch : 20, [0/60000 (0%)]\t Loss : 0.902213\n",
      "Train Epoch : 20, [12800/60000 (21%)]\t Loss : 0.409884\n",
      "Train Epoch : 20, [25600/60000 (43%)]\t Loss : 0.567080\n",
      "Train Epoch : 20, [38400/60000 (64%)]\t Loss : 0.630172\n",
      "Train Epoch : 20, [51200/60000 (85%)]\t Loss : 0.502699\n",
      "[20] Test Loss : 0.5065, Acc : 81.55%\n",
      "Train Epoch : 21, [0/60000 (0%)]\t Loss : 0.705469\n",
      "Train Epoch : 21, [12800/60000 (21%)]\t Loss : 0.757622\n",
      "Train Epoch : 21, [25600/60000 (43%)]\t Loss : 0.589759\n",
      "Train Epoch : 21, [38400/60000 (64%)]\t Loss : 0.808279\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c9f13de1d1e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevalauate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[{}] Test Loss : {:.4f}, Acc : {:.2f}%'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-15b25be34662>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DL\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DL\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DL\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \"\"\"\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DL\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;31m# yikes, this transpose takes 80% of the loading time/CPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1,epochs+1):\n",
    "    train(model,train_loader, optimizer,epoch)\n",
    "    test_loss,test_acc = evalauate(model,test_loader)\n",
    "    \n",
    "    print('[{}] Test Loss : {:.4f}, Acc : {:.2f}%'.format(epoch,test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
