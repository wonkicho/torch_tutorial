{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"seq2seq.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Z6pTnUPtRssoZNQMGB_20fG9PqOcb67b","authorship_tag":"ABX9TyNmbTyR1xmv0Bp5Skjh//Wd"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"8rQd6v3gUm1_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597019153662,"user_tz":-540,"elapsed":955,"user":{"displayName":"WONKI CHO","photoUrl":"","userId":"03303345890609376002"}}},"source":["#german to English\n","#encoder - decoder"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"_HOFG1SwU60o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"status":"error","timestamp":1597023399171,"user_tz":-540,"elapsed":805,"user":{"displayName":"WONKI CHO","photoUrl":"","userId":"03303345890609376002"}},"outputId":"a0854cd5-6d6c-4a67-a686-531aaa80bc64"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from torchtext.datasets import Multi30k\n","#preprocessing\n","from torchtext.data import Field, BucketIterator\n","import numpy as np\n","import spacy\n","import random\n","#텐서보드 출력목적\n","\n","from torch.utils.tensorboard import SummaryWriter\n","from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint"],"execution_count":29,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-c07be98fecf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtranslate_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '__main__.utils'; '__main__' is not a package","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"lUbRvYmSHfdI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":523},"executionInfo":{"status":"ok","timestamp":1597025165611,"user_tz":-540,"elapsed":5414,"user":{"displayName":"WONKI CHO","photoUrl":"","userId":"03303345890609376002"}},"outputId":"5e4c5336-5612-46a4-fa92-a9aeafe8d3c0"},"source":["!python -m spacy download en"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.7.1)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (49.2.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EXA0Q3VUVMFv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597019231986,"user_tz":-540,"elapsed":2885,"user":{"displayName":"WONKI CHO","photoUrl":"","userId":"03303345890609376002"}}},"source":["#tokenizer\n","spacy_ger = spacy.load('de')\n","spacy_en = spacy.load('en')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"1lw-gMJ9WP8P","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597019240758,"user_tz":-540,"elapsed":758,"user":{"displayName":"WONKI CHO","photoUrl":"","userId":"03303345890609376002"}}},"source":["def tokenizer_ger(text):\n","  return [tok.text for tok in spacy_ger.tokenizer(text)]\n","\n","def tokenizer_en(text):\n","  return [tok.text for tok in spacy_en.tokenizer(text)]"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"IPaAM1xraZvq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597019242499,"user_tz":-540,"elapsed":727,"user":{"displayName":"WONKI CHO","photoUrl":"","userId":"03303345890609376002"}}},"source":["german = Field(tokenize = tokenizer_ger, lower=True, init_token='<sos>', eos_token='<eos>')\n","english = Field(tokenize = tokenizer_en, lower=True, init_token='<sos>', eos_token='<eos>')"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"YOzK5PnbazsN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1597019252780,"user_tz":-540,"elapsed":9451,"user":{"displayName":"WONKI CHO","photoUrl":"","userId":"03303345890609376002"}},"outputId":"1d574358-edfb-49c9-9a13-9de1a72cf4f7"},"source":["train_data , valid_data, test_data = Multi30k.splits(exts=('.de', '.en'), fields = (german, english))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["downloading training.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 867kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["downloading validation.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 243kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["downloading mmt_task1_test2016.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 237kB/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"cTuP7J-Wa4Sa","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597019254787,"user_tz":-540,"elapsed":963,"user":{"displayName":"WONKI CHO","photoUrl":"","userId":"03303345890609376002"}}},"source":["#빈도수 2회 이상 단어만 취급\n","german.build_vocab(train_data, max_size=10000, min_freq = 2)\n","english.build_vocab(train_data, max_size=10000, min_freq=2)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"58Ew-x4qb-4s","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597021949107,"user_tz":-540,"elapsed":785,"user":{"displayName":"WONKI CHO","photoUrl":"","userId":"03303345890609376002"}}},"source":["class Encoder(nn.Module):\n","  def __init__(self, input_size, embedding_size, hidden_size, num_layers, dropout):\n","    super(Encoder,self).__init__()\n","    self.num_layers = num_layers\n","    self.hidden_size = hidden_size\n","    self.dropout = nn.Dropout(dropout)\n","    self.embedding = nn.Embedding(input_size, embedding_size)\n","    self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout)\n","\n","\n","  def forward(self, x):\n","    #x shape(seqlen, N)\n","    # emb shape - seqlen, n ,embedding_size\n","    embedding = self.dropout(self.embedding(x))\n","\n","\n","    outputs, (hidden, cell) = self.rnn(embedding)\n","    return hidden, cell\n","\n","class Decoder(nn.Module):\n","  def __init__(self, input_size, embedding_size, hidden_size, output_size,num_layers, dropout):\n","    super(Decoder, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","    self.dropout = nn.Dropout(dropout)\n","    self.embedding = nn.Embedding(input_size, embedding_size)\n","    self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout)\n","    self.fc = nn.Linear(hidden_size, output_size)\n","\n","  def forward(self,x,hidden,cell):\n","    #shape of x : N -> 1,N\n","    #인코더에는 문장이 들어오나 디코더에서는 단어 하나씩 나오기때문에\n","    x = x.unsqueeze(0)\n","    embedding = self.dropout(self.embedding(x))\n","    #emb shape (1,N,emb size), LSTM -> hidden cell state\n","    outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n","    #outputs -> 1, N, hidden size\n","    predictions = self.fc(outputs)\n","    #shape of predictions - > 1,N, length of vocab\n","    predictions = predictions.squeeze(0)\n","\n","    #hidden, cell -> 다음 state에 전달\n","    return predictions, hidden, cell\n","\n","\n","class Seq2Seq(nn.Module):\n","  def __init__(self, encoder, decoder):\n","    super(Seq2Seq, self).__init__()\n","    self.encoder = encoder\n","    self.decoder= decoder\n","\n","  def forward(self, source, target, teacher_force_ratio = 0.5):\n","    batch_size = source.shape[1] # tar_len, N\n","    target_len = target.shape[0]\n","    targat_vocab_size = len(english.vocab)\n","    \n","    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n","    \n","    hidden, cell = self.encoder(source)\n","    \n","    # start token\n","    x = target[0]\n","    for t in range(1, target_len):\n","      output, hidden, cell = self.decoder(x,hidden, cell)\n","      outputs[t] = output\n","      # (N, english_vocab_size)\n","      best_guess = output.argmax(1)\n","      x = target[t] if random.random() <teacher_force_ratio else best_guess\n","\n","    return outputs"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"6EUOFhBvj0ul","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":262},"executionInfo":{"status":"error","timestamp":1597024355101,"user_tz":-540,"elapsed":881,"user":{"displayName":"WONKI CHO","photoUrl":"","userId":"03303345890609376002"}},"outputId":"65bcbcaa-9dcc-4f37-9c6a-348c214deb33"},"source":["\n","\n","#hyperparameters\n","num_epochs = 20\n","learning_rate = 0.001\n","batch_size = 64\n","\n","load_model = False\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","input_size_encoder = len(german.vocab)\n","input_size_decoder = len(english.vocab)\n","output_size = len(english.vocab)\n","encoder_embedding_size = 300\n","decoder_embedding_size = 300\n","hidden_size = 1024\n","\n","num_layers = 2\n","enc_dropout = 0.5\n","dec_dropout = 0.5\n","\n","#tensorboard\n","writer = SummaryWriter(f'runs/loss_plot')\n","step = 0\n","\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","  (train_data, valid_data, test_data), batch_size = batch_size, sort_within_batch = True,\n","  sort_key = lambda x : len(x.src),\n","  device = device\n",")\n","\n","encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout).to(device)\n","decoder_net = Decoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dec_dropout).to(device)\n","\n","\n","model = Seq2Seq(encoder_net, decoder_net).to(device)\n","\n","pad_idx = english.vocab.stoi['<pad>']\n","criterion = nn.CrossEntropyLoss(ignore_index = pad_idx)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","if load_model:\n","  load_checkpoint(torch.load('my_checkpoint.pth.ptar'), model, optimizer)\n","\n","sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\"\n","for epoch in range(num_epochs):\n","  print(f'Epoch [{epoch} / {num_epochs}]')\n","  checkpoint = {'state_dict' : model.state_dict(), 'optimizer':optimizer.state_dict()}\n","  save_checkpoint(checkpoint)\n","  model.eval()\n","\n","  translated_sentence = translate_sentence(model, sentence,german, english, device , max_length=50)\n","\n","  for batch_idx, batch in enumerate(train_iterator):\n","    inp_data = batch.src.to(device)\n","    target = batch.trg.to(device)\n","\n","    output = model(inp_data, target)\n","    #target_len, batch_size, output_dim\n","\n","    #output[0] - > start token\n","    output = output[1:].reshape(-1, output.shape[2])\n","    target = target[1:].reshape(-1)\n","\n","    optimizer.zero_grad()\n","    loss = criterion(output, target)\n","    loss.backward()\n","\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n","    optimizer.step()\n","\n","    writer.add_scalar('Training loss', loss, global_step=step)\n","    step += 1\n","    "],"execution_count":30,"outputs":[{"output_type":"stream","text":["Epoch [0 / 20]\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-73a3963de243>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch [{epoch} / {num_epochs}]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'state_dict'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'save_checkpoint' is not defined"]}]},{"cell_type":"code","metadata":{"id":"oWUiPmij6hVw","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}